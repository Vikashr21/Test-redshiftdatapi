# lambda_function.py
# Runtime: Python 3.11 (or 3.10). Needs boto3 (already in Lambda) + pandas (via a Lambda layer).

import os, time, concurrent.futures as cf
import boto3
import pandas as pd

# --- Env vars (configure in Lambda console) ---
WORKGROUP   = os.environ["REDSHIFT_WORKGROUP"]
DATABASE    = os.environ["REDSHIFT_DATABASE"]
SECRET_ARN  = os.environ["REDSHIFT_SECRET_ARN"]
MAX_CONC    = int(os.getenv("MAX_CONCURRENCY", "4"))  # tune based on RPU
POLL_SECS   = float(os.getenv("POLL_INTERVAL", "0.5"))
STMT_DEADLINE_S = int(os.getenv("STMT_DEADLINE_S", "120"))
# ----------------------------------------------

rsd = boto3.client("redshift-data")

# ---------- helpers ----------
def _param(name, v):
    if v is None: return {"name": name, "isNull": True}
    if isinstance(v, bool): return {"name": name, "booleanValue": v}
    if isinstance(v, int): return {"name": name, "longValue": v}
    if isinstance(v, float): return {"name": name, "doubleValue": v}
    return {"name": name, "stringValue": str(v)}

def _cell_val(cell):
    if cell.get("isNull"): return None
    for k in ("longValue","doubleValue","booleanValue","stringValue"):
        if k in cell: return cell[k]
    return None

def _submit(sql, params=None):
    args = dict(WorkgroupName=WORKGROUP, Database=DATABASE, Sql=sql, WithEvent=True)
    if SECRET_ARN: args["SecretArn"] = SECRET_ARN
    if params: args["Parameters"] = [_param(k, v) for k, v in params.items()]
    return rsd.execute_statement(**args)["Id"]

def _wait(stmt_id, deadline_s=STMT_DEADLINE_S):
    t0 = time.time()
    while True:
        st = rsd.describe_statement(Id=stmt_id)
        if st["Status"] in ("FINISHED","FAILED","ABORTED"):
            if st["Status"] != "FINISHED":
                raise RuntimeError(f"{st['Status']}: {st.get('Error')}")
            return
        if time.time() - t0 > deadline_s:
            rsd.cancel_statement(Id=stmt_id)
            raise TimeoutError(f"Timed out waiting for {stmt_id}")
        time.sleep(POLL_SECS)

def _fetch_all(stmt_id):
    cols, rows, token = [], [], None
    while True:
        page = rsd.get_statement_result(Id=stmt_id, NextToken=token) if token else rsd.get_statement_result(Id=stmt_id)
        if not cols:
            cols = [c["name"] for c in page["ColumnMetadata"]]
        for rec in page["Records"]:
            rows.append([_cell_val(c) for c in rec])
        token = page.get("NextToken")
        if not token: break
    return pd.DataFrame(rows, columns=cols)

def select_df(sql, params=None):
    stmt_id = _submit(sql, params=params)
    _wait(stmt_id)
    return _fetch_all(stmt_id)

def run_parallel_selects(jobs, max_concurrency=MAX_CONC):
    """
    jobs = [{"name": "q1", "sql": "SELECT ..."}, ...]
    Returns {name: DataFrame}
    """
    out = {}
    def _one(job): return job["name"], select_df(job["sql"], job.get("params"))
    with cf.ThreadPoolExecutor(max_workers=max_concurrency) as pool:
        futs = {pool.submit(_one, j): j for j in jobs}
        for fut in cf.as_completed(futs):
            name, df = fut.result()
            out[name] = df
    return out

# -------- Lambda entry --------
def lambda_handler(event, context):
    """
    Event example:
    {
      "jobs": [
        {"name": "users_top2", "sql": "SELECT id, name FROM public.users LIMIT 2"},
        {"name": "orders_top", "sql": "SELECT user_id, COUNT(*) AS orders FROM public.orders GROUP BY 1 ORDER BY 2 DESC LIMIT 5"},
        {"name": "now", "sql": "SELECT current_timestamp AS ts_utc"}
      ]
    }
    """
    jobs = event.get("jobs") or []
    if not jobs:
        jobs = [{"name": "now", "sql": "SELECT current_timestamp AS ts_utc"}]

    dfs = run_parallel_selects(jobs)

    # Print each DataFrame (goes to CloudWatch logs)
    for name, df in dfs.items():
        print(f"\n=== {name} ===")
        print(df)

    # Optionally return the results inline (as JSON serializable)
    result = {name: df.to_dict(orient="records") for name, df in dfs.items()}
    return {"statusCode": 200, "body": result}
